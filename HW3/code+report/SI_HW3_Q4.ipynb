{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sJAJwS77g9Hd"
      },
      "source": [
        "# **Part 1:**\n",
        "we will calculate the marginal probabilities for each row and column and then check whether the product of the marginal probabilities for each cell equals the corresponding p_ij.\n",
        "\n",
        "The calculations confirm that the observed probabilities match the expected probabilities under the null hypothesis of independence for each cell of the table. Specifically, the product of the marginal probabilities for each row and column is equal to the joint probability for each cell.\n",
        "\n",
        "This indicates that the rows and columns in the given table are indeed independent, satisfying the null hypothesis. The table of observed probabilities matches the table of expected probabilities under the null hypothesis, and the boolean array confirms that all corresponding elements are equal, validating the hypothesis of independence.We fail to reject the null hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz1CftDbepdE",
        "outputId": "2dbbce6f-9765-42a9-f507-d62d636c5945"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[[0.15, 0.15],\n",
              "         [0.09, 0.09],\n",
              "         [0.06, 0.06]],\n",
              " \n",
              "        [[0.15, 0.15],\n",
              "         [0.09, 0.09],\n",
              "         [0.06, 0.06]],\n",
              " \n",
              "        [[0.2 , 0.2 ],\n",
              "         [0.12, 0.12],\n",
              "         [0.08, 0.08]]]),\n",
              " array([[ True,  True,  True],\n",
              "        [ True,  True,  True],\n",
              "        [ True,  True,  True]]))"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Observed probabilities from the 3x3 table\n",
        "observed_probabilities = np.array([\n",
        "    [0.15, 0.09, 0.06],\n",
        "    [0.15, 0.09, 0.06],\n",
        "    [0.20, 0.12, 0.08]\n",
        "])\n",
        "\n",
        "# Calculate the marginal probabilities for rows (pi.) and columns (p.j)\n",
        "marginal_rows = observed_probabilities.sum(axis=1)\n",
        "marginal_columns = observed_probabilities.sum(axis=0)\n",
        "\n",
        "# Calculate the expected probabilities under the null hypothesis of independence (pi. * p.j)\n",
        "expected_probabilities = np.outer(marginal_rows, marginal_columns)\n",
        "\n",
        "# Create a table to compare observed and expected probabilities\n",
        "comparison_table = np.dstack((observed_probabilities, expected_probabilities))\n",
        "\n",
        "comparison_table, np.isclose(observed_probabilities, expected_probabilities)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az9J-OUPphUU"
      },
      "source": [
        "# **Part 2:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZQHMeVSmrfs",
        "outputId": "9a1f34e8-a7df-4ef0-e922-0abd850da74a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[52, 29, 17],\n",
              "       [43, 23, 20],\n",
              "       [54, 43, 19]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to classify each pseudo-random number into one of the nine cells\n",
        "def classify_number(x, cumulative_probabilities):\n",
        "    # Find the index of the first cumulative probability that is greater than the random number\n",
        "    cell = np.where(cumulative_probabilities > x)[0][0]\n",
        "    return cell\n",
        "\n",
        "# Observed probabilities from the 3x3 table (flattened for easier cumulative probability calculation)\n",
        "observed_probabilities_flat = np.array([0.15, 0.09, 0.06, 0.15, 0.09, 0.06, 0.20, 0.12, 0.08])\n",
        "\n",
        "# Generate the cumulative probability thresholds for the flattened probabilities\n",
        "cumulative_probabilities = np.cumsum(observed_probabilities_flat)\n",
        "\n",
        "# Number of observations to generate\n",
        "num_observations = 300\n",
        "\n",
        "# Generate 300 pseudo-random numbers between 0 and 1\n",
        "random_numbers = np.random.uniform(0, 1, num_observations)\n",
        "\n",
        "# Initialize an array to hold the counts for each cell\n",
        "cell_counts_corrected = np.zeros(9, dtype=int)\n",
        "\n",
        "# Classify each pseudo-random number into the nine cells based on the cumulative probabilities\n",
        "for x in random_numbers:\n",
        "    cell = classify_number(x, cumulative_probabilities)\n",
        "    cell_counts_corrected[cell] += 1\n",
        "\n",
        "# Reshape the counts to the 3x3 table format\n",
        "sample_observations_corrected = cell_counts_corrected.reshape(3, 3)\n",
        "sample_observations_corrected\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRCh2iyplyw"
      },
      "source": [
        "# **Part 3:**\n",
        "in note."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdqneOsaqLir"
      },
      "source": [
        "# **Part 4:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_jzDENeqEAv",
        "outputId": "7d3ce603-7b85-4dfe-8f0a-18d3f44ec887"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5.66666666666667,\n",
              " 0.22546314129598105,\n",
              " array([9, 2, 4, 7, 8]),\n",
              " array([6., 6., 6., 6., 6.]),\n",
              " array([0.        , 1.64877662, 2.75284268, 4.04462649, 5.98861669,\n",
              "               inf]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Function to simulate observed Q values and perform the goodness-of-fit test\n",
        "def test_chi_squared_goodness_of_fit(observed_values, df, num_bins):\n",
        "    # Calculate the chi-squared distribution with df degrees of freedom\n",
        "    chi2_distribution = stats.chi2(df=df)\n",
        "\n",
        "    # Use the percent point function to find the chi2 values that correspond to the desired percentiles\n",
        "    bin_edges = chi2_distribution.ppf(np.linspace(0, 1, num_bins + 1))\n",
        "\n",
        "    # The expected frequency for each bin, assuming the chi-squared distribution\n",
        "    expected_probs = chi2_distribution.cdf(bin_edges[1:]) - chi2_distribution.cdf(bin_edges[:-1])\n",
        "    expected_frequencies = expected_probs * len(observed_values)\n",
        "\n",
        "    # Binning the observed Q values according to the defined bins\n",
        "    observed_frequencies, _ = np.histogram(observed_values, bins=bin_edges)\n",
        "\n",
        "    # Perform the chi-squared goodness-of-fit test\n",
        "    chi2_statistic, p_value = stats.chisquare(observed_frequencies, f_exp=expected_frequencies)\n",
        "\n",
        "    return chi2_statistic, p_value, observed_frequencies, expected_frequencies, bin_edges\n",
        "\n",
        "# Generate a sample of Q values using a chi-squared distribution with 4 degrees of freedom for demonstration\n",
        "np.random.seed(0)  # Seed for reproducibility\n",
        "simulated_observed_Q_values = np.random.chisquare(4, size=30)\n",
        "\n",
        "# Perform the test with the simulated observed Q values\n",
        "chi2_statistic, p_value, observed_freq, expected_freq, bin_edges = test_chi_squared_goodness_of_fit(\n",
        "    simulated_observed_Q_values, df=4, num_bins=5\n",
        ")\n",
        "\n",
        "chi2_statistic, p_value, observed_freq, expected_freq, bin_edges\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8FLS-0LtWqP"
      },
      "source": [
        "The results from the execution of this code are as follows:\n",
        "\n",
        "Chi-Squared Statistic:\n",
        "χ2≈5.67\n",
        "p-value:\n",
        "≈\n",
        "p≈0.225\n",
        "Observed Frequencies: [9, 2, 4, 7, 8]\n",
        "Expected Frequencies: [6.0, 6.0, 6.0, 6.0, 6.0]\n",
        "Bin Edges: [0.0, 1.65, 2.75, 4.04, 5.99, inf]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
